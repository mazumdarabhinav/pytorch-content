{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/abhinavmazzu/1-pytorch-basics-tensors-and-gradients?scriptVersionId=104707089\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import pandas as pd\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-01T17:43:45.124499Z","iopub.execute_input":"2022-09-01T17:43:45.124942Z","iopub.status.idle":"2022-09-01T17:43:46.860426Z","shell.execute_reply.started":"2022-09-01T17:43:45.124909Z","shell.execute_reply":"2022-09-01T17:43:46.858997Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Tensors\n\nAt its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with a single number.","metadata":{}},{"cell_type":"code","source":"t1 = torch.tensor(4.)\nt1","metadata":{"execution":{"iopub.status.busy":"2022-09-01T17:53:53.823511Z","iopub.execute_input":"2022-09-01T17:53:53.82394Z","iopub.status.idle":"2022-09-01T17:53:53.831525Z","shell.execute_reply.started":"2022-09-01T17:53:53.823909Z","shell.execute_reply":"2022-09-01T17:53:53.830215Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"tensor(4.)"},"metadata":{}}]},{"cell_type":"markdown","source":"`4.` is a shorthand for `4.0`. It is used to indicate to Python (and PyTorch) that you want to create a floating-point number. We can verify this by checking the `dtype` attribute of our tensor.","metadata":{}},{"cell_type":"code","source":"t1.dtype","metadata":{"execution":{"iopub.status.busy":"2022-09-01T17:54:02.750601Z","iopub.execute_input":"2022-09-01T17:54:02.751583Z","iopub.status.idle":"2022-09-01T17:54:02.75959Z","shell.execute_reply.started":"2022-09-01T17:54:02.751553Z","shell.execute_reply":"2022-09-01T17:54:02.758078Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"torch.float32"},"metadata":{}}]},{"cell_type":"code","source":"# Vector\nt2 = torch.tensor([1.0, 2, 3, 4])\nt2","metadata":{"execution":{"iopub.status.busy":"2022-09-01T17:55:57.480561Z","iopub.execute_input":"2022-09-01T17:55:57.481027Z","iopub.status.idle":"2022-09-01T17:55:57.489933Z","shell.execute_reply.started":"2022-09-01T17:55:57.48099Z","shell.execute_reply":"2022-09-01T17:55:57.488535Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"tensor([1., 2., 3., 4.])"},"metadata":{}}]},{"cell_type":"code","source":"t2.dtype","metadata":{"execution":{"iopub.status.busy":"2022-09-01T17:56:05.662914Z","iopub.execute_input":"2022-09-01T17:56:05.663345Z","iopub.status.idle":"2022-09-01T17:56:05.669316Z","shell.execute_reply.started":"2022-09-01T17:56:05.663309Z","shell.execute_reply":"2022-09-01T17:56:05.66852Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"torch.float32"},"metadata":{}}]},{"cell_type":"code","source":"# Matrix\nt3 = torch.tensor([[5., 6], [7,8], [9, 10]])\nt3, t3.dtype","metadata":{"execution":{"iopub.status.busy":"2022-09-01T17:57:28.955647Z","iopub.execute_input":"2022-09-01T17:57:28.956106Z","iopub.status.idle":"2022-09-01T17:57:28.964227Z","shell.execute_reply.started":"2022-09-01T17:57:28.956072Z","shell.execute_reply":"2022-09-01T17:57:28.96313Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(tensor([[ 5.,  6.],\n         [ 7.,  8.],\n         [ 9., 10.]]),\n torch.float32)"},"metadata":{}}]},{"cell_type":"code","source":"# 3-dimensional array\nt4 = torch.tensor([\n    [[11, 12, 13], \n     [13, 14, 15]], \n    [[15, 16, 17], \n     [17, 18, 19.]]])\nt4, t4.dtype","metadata":{"execution":{"iopub.status.busy":"2022-09-01T17:57:56.157301Z","iopub.execute_input":"2022-09-01T17:57:56.157698Z","iopub.status.idle":"2022-09-01T17:57:56.168499Z","shell.execute_reply.started":"2022-09-01T17:57:56.157673Z","shell.execute_reply":"2022-09-01T17:57:56.167529Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(tensor([[[11., 12., 13.],\n          [13., 14., 15.]],\n \n         [[15., 16., 17.],\n          [17., 18., 19.]]]),\n torch.float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"Tensors can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the `.shape` property of a tensor.","metadata":{}},{"cell_type":"code","source":"t1.shape, t2.shape, t3.shape, t4.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-01T18:00:55.628138Z","iopub.execute_input":"2022-09-01T18:00:55.629252Z","iopub.status.idle":"2022-09-01T18:00:55.635995Z","shell.execute_reply.started":"2022-09-01T18:00:55.62922Z","shell.execute_reply":"2022-09-01T18:00:55.635214Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(torch.Size([]), torch.Size([4]), torch.Size([3, 2]), torch.Size([2, 2, 3]))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Tensor operations and gradients\n\nWe can combine tensors with the usual arithmetic operations. Let's look at an example:","metadata":{}},{"cell_type":"code","source":"# create tensor\nx = torch.tensor(3.)\nw = torch.tensor(4., requires_grad=True)\nb = torch.tensor(5., requires_grad=True)\n\nx, w, b","metadata":{"execution":{"iopub.status.busy":"2022-09-01T18:07:45.609148Z","iopub.execute_input":"2022-09-01T18:07:45.610179Z","iopub.status.idle":"2022-09-01T18:07:45.618827Z","shell.execute_reply.started":"2022-09-01T18:07:45.610119Z","shell.execute_reply":"2022-09-01T18:07:45.617807Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"},"metadata":{}}]},{"cell_type":"markdown","source":"We've created three tensors: `x`, `w`, and `b`, all numbers. `w` and `b` have an additional parameter `requires_grad` set to `True`. We'll see what it does in just a moment. \n\nLet's create a new tensor `y` by combining these tensors.","metadata":{}},{"cell_type":"code","source":"# arithmetic operations\ny = w * x + b\ny","metadata":{"execution":{"iopub.status.busy":"2022-09-01T18:29:47.887799Z","iopub.execute_input":"2022-09-01T18:29:47.888253Z","iopub.status.idle":"2022-09-01T18:29:47.895725Z","shell.execute_reply.started":"2022-09-01T18:29:47.88822Z","shell.execute_reply":"2022-09-01T18:29:47.894863Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor(17., grad_fn=<AddBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"As expected, `y` is a tensor with the value `3 * 4 + 5 = 17`. What makes PyTorch unique is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. w and b. This feature of PyTorch is called _autograd_ (automatic gradients).\n\nTo compute the derivatives, we can invoke the `.backward` method on our result `y`.","metadata":{}},{"cell_type":"code","source":"# compute derivatives\ny.backward()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T18:31:16.481705Z","iopub.execute_input":"2022-09-01T18:31:16.482157Z","iopub.status.idle":"2022-09-01T18:31:16.49492Z","shell.execute_reply.started":"2022-09-01T18:31:16.482125Z","shell.execute_reply":"2022-09-01T18:31:16.49414Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"The derivatives of `y` with respect to the input tensors are stored in the `.grad` property of the respective tensors.","metadata":{}},{"cell_type":"code","source":"# Display gradients\nprint('dy/dx:', x.grad)\nprint('dy/dw:', w.grad)\nprint('dy/db:', b.grad)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T18:32:33.299117Z","iopub.execute_input":"2022-09-01T18:32:33.299518Z","iopub.status.idle":"2022-09-01T18:32:33.306359Z","shell.execute_reply.started":"2022-09-01T18:32:33.299488Z","shell.execute_reply":"2022-09-01T18:32:33.30537Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"dy/dx: None\ndy/dw: tensor(3.)\ndy/db: tensor(1.)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As expected, `dy/dw` has the same value as `x`, i.e., `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None` because `x` doesn't have `requires_grad` set to `True`. \n\nThe \"grad\" in `w.grad` is short for _gradient_, which is another term for derivative. The term _gradient_ is primarily used while dealing with vectors and matrices.","metadata":{}},{"cell_type":"markdown","source":"## Interoperability with Numpy\n\n[Numpy](http://www.numpy.org/) is a popular open-source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n\n* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n* [OpenCV](https://opencv.org/) for image and video processing\n\n\nIf you're interested in learning more about Numpy and other data science libraries in Python, check out this tutorial series: https://jovian.ai/aakashns/python-numerical-computing-with-numpy .\n\nInstead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nx = np.array([[1, 2], [3, 4.]])\nx","metadata":{"execution":{"iopub.status.busy":"2022-09-01T18:37:58.675142Z","iopub.execute_input":"2022-09-01T18:37:58.67552Z","iopub.status.idle":"2022-09-01T18:37:58.683826Z","shell.execute_reply.started":"2022-09-01T18:37:58.675493Z","shell.execute_reply":"2022-09-01T18:37:58.682803Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([[1., 2.],\n       [3., 4.]])"},"metadata":{}}]},{"cell_type":"markdown","source":"We can convert a Numpy array to a PyTorch tensor using `torch.from_numpy`.","metadata":{}},{"cell_type":"code","source":"# Convert the numpy array to a torch tensor.\ny = torch.from_numpy(x)\ny","metadata":{"execution":{"iopub.status.busy":"2022-09-01T18:38:30.007666Z","iopub.execute_input":"2022-09-01T18:38:30.008224Z","iopub.status.idle":"2022-09-01T18:38:30.014414Z","shell.execute_reply.started":"2022-09-01T18:38:30.008194Z","shell.execute_reply":"2022-09-01T18:38:30.01363Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"tensor([[1., 2.],\n        [3., 4.]], dtype=torch.float64)"},"metadata":{}}]},{"cell_type":"code","source":"x.dtype, y.dtype","metadata":{"execution":{"iopub.status.busy":"2022-09-01T18:38:57.227517Z","iopub.execute_input":"2022-09-01T18:38:57.227959Z","iopub.status.idle":"2022-09-01T18:38:57.234634Z","shell.execute_reply.started":"2022-09-01T18:38:57.227931Z","shell.execute_reply":"2022-09-01T18:38:57.233704Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(dtype('float64'), torch.float64)"},"metadata":{}}]},{"cell_type":"markdown","source":"We can convert a PyTorch tensor to a Numpy array using the `.numpy` method of a tensor.","metadata":{}},{"cell_type":"code","source":"# Convert a torch tensor to a numpy array\nz = y.numpy()\nz","metadata":{"execution":{"iopub.status.busy":"2022-09-01T18:40:51.34803Z","iopub.execute_input":"2022-09-01T18:40:51.348599Z","iopub.status.idle":"2022-09-01T18:40:51.354893Z","shell.execute_reply.started":"2022-09-01T18:40:51.348566Z","shell.execute_reply":"2022-09-01T18:40:51.354076Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"array([[1., 2.],\n       [3., 4.]])"},"metadata":{}}]},{"cell_type":"markdown","source":"The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n\nYou might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n\n1. **Autograd**: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n2. **GPU support**: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.\n\nWe'll leverage both these features of PyTorch extensively in this tutorial series.","metadata":{"execution":{"iopub.status.busy":"2022-09-01T18:42:19.819155Z","iopub.execute_input":"2022-09-01T18:42:19.819747Z","iopub.status.idle":"2022-09-01T18:42:19.828278Z","shell.execute_reply.started":"2022-09-01T18:42:19.819714Z","shell.execute_reply":"2022-09-01T18:42:19.826609Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}